---
title: "CommonWords and WordCloud from each Class"
author: "Stacey Do"
date: "2023-03-22"
output: html_document
---
#library
library(tidyverse)
library(ggplot2)
library(ggwordcloud)
unique(train$class) #class = " ", figurative, irony, regular, and sarcasm



```{r setup}
library('stopwords')
library('tidyverse')
library('ggplot2')
library('ggwordcloud')
#library('readxl')



```




```{r load_dataset}
train <- read.csv('Datasets/Tweets_with_Sarcasm_and_Irony/train.csv')
test <- read.csv('Datasets/Tweets_with_Sarcasm_and_Irony/test.csv')
```




#Filter tweets with their classes
```{r eval=FALSE}
figurativeSet <- filter(train, class=="figurative")

ironySet <- filter(train, class == "irony")

sarcasmSet <- filter(train, class =="sarcasm")

regularSet <- filter(train, class =="regular")


not_regularSet <- filter(train, class != "regular")
```
#Collect the words and their frequencies from the set
```{r eval=FALSE}
freq_figurative <- as.data.frame(sort(table(unlist(strsplit(figurativeSet$tweets," "))), decreasing = TRUE), stringsAsFactors = FALSE)
summary(freq_figurative)

freq_irony <- as.data.frame(sort(table(unlist(strsplit(ironySet$tweets," "))), decreasing = TRUE), stringsAsFactors = FALSE)

freq_sarcasm <- as.data.frame(sort(table(unlist(strsplit(sarcasmSet$tweets," "))), decreasing = TRUE), stringsAsFactors = FALSE)

freq_regular <- as.data.frame(sort(table(unlist(strsplit(regularSet$tweets," "))), decreasing = TRUE), stringsAsFactors = FALSE)

freq_not_regular <- as.data.frame(sort(table(unlist(strsplit(not_regularSet$tweets," "))), decreasing = TRUE), stringsAsFactors = FALSE)
```

#Key objects: frequency sets

#make the word cloud of each list
#Figurative word cloud
#Since there's over 34,000 tibbles it wouldn't make a wordcloud due to the length in processing
#So take a subset of the data where we select only the words with 100+ frequencies
```{r eval=FALSE}

dfSubsetFigurative <- subset(freq_figurative, Freq > 100, stringsAsFactors = FALSE)

dfSubsetIrony <- subset(freq_irony, Freq > 100, stringsAsFactors = FALSE)

dfSubsetSarcasm <- subset(freq_sarcasm, Freq > 100, stringsAsFactors = FALSE)

dfSubsetRegular <- subset(freq_regular, Freq > 100, stringsAsFactors = FALSE)
```


#Now to make the wordcloud
#Code: 
```{r eval=FALSE}
#figurative
set.seed(42)
ggplot(dfSubsetFigurative, aes(label = Var1, size = length(Var1), color = Var1)) +
  geom_text_wordcloud_area(eccentricity = .35) +
  scale_size_area(max_size = 24) +
  theme_minimal() 

#irony 
set.seed(42)
ggplot(dfSubsetIrony, aes(label = Var1, size = length(Var1), color = Var1)) +
  geom_text_wordcloud_area(eccentricity = .35) +
  scale_size_area(max_size = 24) +
  theme_minimal() 

#sarcasm
set.seed(42)
ggplot(dfSubsetSarcasm, aes(label = Var1, size = length(Var1), color = Var1)) +
  geom_text_wordcloud_area(eccentricity = .35) +
  scale_size_area(max_size = 24) +
  theme_minimal() 

#regular
set.seed(42)
ggplot(dfSubsetRegular, aes(label = Var1, size = length(Var1), color = Var1)) +
  geom_text_wordcloud_area(eccentricity = .35) +
  scale_size_area(max_size = 24) +
  theme_minimal() 
```

```{r echo=FALSE}
#library
#train <- read_excel("D:\\OneDrive - SUNY Brockport\\Spring 2023-LAPTOP-4BPR9F3O\\Data Analysis\\Tweety Project\\trainXL.xlsx")

#Filter tweets with their classes
figurativeSet <- filter(train, class=="figurative")

ironySet <- filter(train, class == "irony")

sarcasmSet <- filter(train, class =="sarcasm")

regularSet <- filter(train, class =="regular")
#Collect the words and their frequencies from the set

freq_figurative <- as.data.frame(sort(table(unlist(strsplit(figurativeSet$tweets," "))), decreasing = TRUE), stringsAsFactors = FALSE)

freq_irony <- as.data.frame(sort(table(unlist(strsplit(ironySet$tweets," "))), decreasing = TRUE), stringsAsFactors = FALSE)

freq_sarcasm <- as.data.frame(sort(table(unlist(strsplit(sarcasmSet$tweets," "))), decreasing = TRUE), stringsAsFactors = FALSE)

freq_regular <- as.data.frame(sort(table(unlist(strsplit(regularSet$tweets," "))), decreasing = TRUE), stringsAsFactors = FALSE)


#Key objects: frequency sets

#make the word cloud of each list
  #Figurative word cloud
#Since there's over 34,000 tibbles it wouldn't make a word cloud due to the length in processing
#So take a subset of the data where we select only the words with 100+ frequencies

dfSubsetFigurative <- subset(freq_figurative, Freq > 100, stringsAsFactors = FALSE)

dfSubsetIrony <- subset(freq_irony, Freq > 100, stringsAsFactors = FALSE)

dfSubsetSarcasm <- subset(freq_sarcasm, Freq > 100, stringsAsFactors = FALSE)

dfSubsetRegular <- subset(freq_regular, Freq > 100, stringsAsFactors = FALSE)

#wordclouds

#figurative
set.seed(42)
ggplot(dfSubsetFigurative, aes(label = Var1, size = length(Var1), color = Var1)) +
  geom_text_wordcloud_area(eccentricity = .35) +
  scale_size_area(max_size = 24) +
  theme_minimal() 

#irony 
set.seed(42)
ggplot(dfSubsetIrony, aes(label = Var1, size = length(Var1), color = Var1)) +
  geom_text_wordcloud_area(eccentricity = .35) +
  scale_size_area(max_size = 24) +
  theme_minimal() 

#sarcasm
set.seed(42)
ggplot(dfSubsetSarcasm, aes(label = Var1, size = length(Var1), color = Var1)) +
  geom_text_wordcloud_area(eccentricity = .35) +
  scale_size_area(max_size = 24) +
  theme_minimal() 

#regular
set.seed(42)
ggplot(dfSubsetRegular, aes(label = Var1, size = length(Var1), color = Var1)) +
  geom_text_wordcloud_area(eccentricity = .35) +
  scale_size_area(max_size = 24) +
  theme_minimal() 

```


```{r}
freq_figurative
frequencys <- full_join(freq_figurative,freq_irony, by = "Var1") %>%
  full_join(freq_regular, by = "Var1") %>%
  full_join(freq_sarcasm, by = "Var1") %>%
  rename(figurative = Freq.x,
         irony = Freq.y,
         regular = Freq.x.x,
         sarcasm = Freq.y.y)


frequencys_2_class <-  full_join(freq_regular,freq_not_regular, by = "Var1") %>%
   rename(regular = Freq.x,
         not_regular = Freq.y)


frequencys_2_class[frequencys_2_class == 0] <- 1
frequencys_2_class[is.na(frequencys_2_class)] <- 1


frequencys[frequencys == 0] <- 1
frequencys[is.na(frequencys)] <- 1

frequencys <- frequencys %>%
  mutate(figurative_prop = figurative/(irony * regular * sarcasm)) %>%
  mutate(irony_prop = irony/(figurative * regular * sarcasm)) %>%
  mutate(sarcasm_prop = sarcasm/(figurative * regular * irony)) %>%
  mutate(regular_prop = regular/(figurative * sarcasm * irony)) 


frequencys_2_class <- frequencys_2_class %>% 
  mutate(prop = regular/not_regular) %>%
  mutate(inv_prop = not_regular/regular)



max = 60
#graph_freq <- function(df, max_entries = 60) {
  frequencys %>% 
  arrange(desc(regular_prop)) %>%
  slice(1:max) %>%
  ggplot(aes(y = regular_prop, x = reorder(Var1, order(regular_prop, decreasing = TRUE)))) +
  geom_bar(stat='identity') +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
#}

  frequencys_2_class %>% 
  arrange(desc(prop)) %>%
  slice(1:max) %>%
  ggplot(aes(y = prop, x = reorder(Var1, order(prop, decreasing = TRUE)))) +
  geom_bar(stat='identity') +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

  


```

```{r}


max = 60
frequencys_tmp_prop <- frequencys_2_class %>%
  arrange(desc(prop)) %>%
  slice(1:max)

frequencys_tmp_inv_prop <- frequencys_2_class %>%
  arrange(desc(inv_prop)) %>%
  slice(1:max)


ggplot(frequencys_tmp_prop, aes(label = Var1, size = prop)) +
  geom_text_wordcloud_area(eccentricity = .54, color = 'red') +
  #scale_size_area(max_size = 30) +
  theme_minimal() +  
  ggtitle ('Words found in tweets that are considered regular')

ggplot(frequencys_tmp_inv_prop, aes(label = Var1, size = inv_prop)) +
  geom_text_wordcloud_area(eccentricity = .54, color = 'blue') +
  #scale_size_area(max_size = 30) +
  theme_minimal() +  
  ggtitle ('Words found in tweets that are not considered regular (irony, figurative, sarcasm)')
  





```

